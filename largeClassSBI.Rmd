---
title: "Thoughts on teaching an SBI course for a large class"
author: "Matthew Beckman"
date: "8/24/2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## What this is & what this isn't

This post is intended share some pragmatic thoughts for *teaching* SBI in a large class, and not necessarily converting your curriculum to the SBI framework.  A number of suggestions on the latter have been published in this blog and elsewhere.  Besides, my colleague--Kari Lock Morgan--had already done a remarkable job accomplishing that feat in the course to be described before I arrived. What follows are simply remarks about rubber-meets-the-road strategies from teaching an SBI course with 225 students to either capitalize on large class size or at least help navigate some logistical challenges that surface with increased enrollment. 

## A familiar activity scaled for a large class

While teaching smaller classes, I adopted a popular illustration with M&M's (sometimes Skittles) to introduce bootstrapping. I didn't invent or perfect the activity, but here's a summary:  Each student gets a fun size bag of M&M's, calculates the proportion of blue, and then marks the result on a class dotplot in front of the room. We can now have a conversation about a sampling distribution under the assumption that each fun size bag represents a random sample of M&M's. We emphasize the point that each mark on the dotplot represents a statistic calculated from an actual sample in the room, and perhaps point out a few (say, extremes) and identify the responsible students to emphasize the point. 

Students then sample with replacement from their own bag to build a bootstrap distribution.  Students do this a few times by hand, and then introduce software to speed things up. We emphasize that each dot in the bootstrap distribution is now a proportion of blue M&M's out of 16 draws with replacement from their own fun size bag (assuming 16 is the sample size contained).  We highlight similarities and differences between the sampling distribution and bootstrap distributions. For example, bootstrap distributions will generally be centered in different places, but still wind up with a useful estimate of standard error.

I tend to get a lot of mileage out of this activity as the semester progresses.  When I sense that students are losing sight of the fundamentals, we periodically back up and talk about the M&M's again to get back on solid footing.  

The thought of scaling this for 225 students was daunting at first, but since I like having this example in my back pocket later in the semester it was worth a shot. To start, I basically buy the entire stock of fun-size M&M's available at a super-store in town. We'll have plenty of M&Ms in the room to make our point, so I also supplement with an alternative of some kind for those who don't want/can't eat M&M's.

The student dotplot is really the main hurdle here.  With 225 students in fixed seating, a human wave filing down the aisles to mark the chalk board is a non-starter so we use Google Sheets or Forms. Students use a smart phone to access a shortened link (e.g. tiny.cc) or scan a QR code displayed on the front screen to access the spreadsheet/form and enter their result from their seats.  After a quick filter, I cut and paste the data into software, and make our class dotplot.  From start to finish, this method in a large class might even be faster than the manual approach I had used in smaller classes.  

## A few themes...

Of course this is just one specific activity, but there are some themes here that apply to lots of activies.  

**Try it anyway.**  The "worst case scenarios" that I concoct when I imagine attempting an activity developed for small classes never really seem to happen. I probably fear that the mild noise, mess, and chaos of smaller classes will escalate into a completely wasted class period with so many students.  Thankfully, that hasn't happened (...yet?) largely because a little technology can neutralize the few inflection points where things would most likely derail (e.g. 225 students physically marking the chalkboard).   

**Redeem the smart phone!**  Don't underestimate the tiny computers that most of your students already bring to class.  QR codes--those pixelated square codes you scan--and shortened URLs (e.g. tiny.cc; bit.ly) can direct students to an applet, Google Sheet (Form, Doc, etc), or anything else on the web right from their seats.  Students can even share with a neighbor or look over the shoulder in front of them--particularly in stadium seat lecture halls.  As another example, my class uses the Lock5 text and the accompanying StatKey software works great on a smart phone.  I can introduce authentic data analysis tasks during "lecture" for  students to tackle in pairs; one runs StatKey, the other takes notes.

**The large enrollment actually has some perks.**  Since the class is large, class data sets are that much closer to Asymptopia. I'm sure I'm not the only one who's attempted to use a class plot to lay the groundwork for the CLT and wound up with a skewed or bimodal-looking mess that looks nothing like the bell-shape I had in mind... Furthermore, rare events and oddities that lead to interesting discussions almost always show up.  Someone will enter the count rather than proportion, and someone else usually observes something rare just by chance. Since I'm the gatekeeper for the class plot, I decide whether there's time to discuss data entry errors or if we need to filter them out and plow ahead in the interest of time. Also, a student with no blue M&Ms, for example, isn't hypothetical or a mistake. Rare events in the tails of the distribution really do happen! 

**Keep an eye toward the big picture.** You'll rarely need 100% cooperation to make your point. For example, in the M&M activity some students eat the candy before we start, others won't get to the spreadsheet in time, and some didn't get M&M's to begin with! Even if only 50 students fully participate (< 25% in my case), the illustration still serves it's purpose and benefits the whole class.  



\iffalse
[Block Comment]

### Thought #2: Crowd-source


- the asymptotic point you want to make from student data is more likely to work
- "unusual" stuff like typos, wrong units, and other anomalies happens EVERY time
    - valuable teachable moment... this just happened, it's not hypothetical
    - easy to clean up & filter out, so any delay is trivial
- (M&Ms) 
    - we're the sampling distribution
    - you're the bootstrap distritubion

- Large sample size for student generated data (GAISE, 2016)
    - reliable demonstrations of asymptotic properties (e.g. CLT) using data generated in-class
    - unusual observations often generated in-class
        - outliers (e.g. wrong units & typos)
        - legitimate extreme obs. (the tails are real)
        - sensitivity analysis discussions


### Thought #3: Redeem the Smartphone!

- Example: StatKey on smart phones (during lecture)  
    - accessible & scalable technology integration  
    - partner work (one run the app; one take notes)  
- QR codes or bit.ly links
- live SMS inbox

### Thought #4: Yes, I know about the clickers

I actually like the clickers, and do use them regularly in class. They really are a great tool, but early in my quest for good pedagogy that scales to the large class environment it seemed like everyone I approached led with "Are you using clickers?"  Again, they're great, but *are clickers really the best we've got?*  As a result, I confess I began to develop an association between clickers and a certain dissapointment.  



### Thought #5: You don't have to go it alone.

- talk to others... in statistics, but also not just in statistics.  Good teachers with good ideas are everywhere
- GAISE has progressively beefed up the large class game with each iteration; 
- GAISE (2016) includes much more support for large classes




## First, a bit of background. 

I was lucky enough to get my start teaching simulation-based inference (SBI) in the introductory statistics curriculum as a graduate instructor in perhaps the ideal teaching lab environment toward the end of my PhD program.  The class was small--maybe 24 graduate students from non-quantitative disciplines.  We met in a brand new classroom with several 6-seat round tables each with power access, display cables, and a dedicated plasma screen so someone at every table could present simultaneously.  The students were highly engaged and motivated, the technology fell into my lab, and I had access to infinitely valuable mentors as well as a cadre of their graduate students (my peers) to call upon.  We even [wrote a post together for this very blog (link)](https://www.causeweb.org/sbi/?p=422#more-422)!  Clearly, this was a soft landing for my first exposure to teaching SBI, which I thought to be a compelling approach despite the radical departure from my earlier convictions when I began teaching statistics as adjunct faculty 5-6 years prior. 

## My first large class.

Fast-forward a few years to my first semester in a full-time faculty position at Penn State University.  My very first teaching assignment was an introductory biostatistics course with 230 students enrolled.  The class met in a traditional lecture hall with fixed seating and a quarter-circle writing surface attached to each armrest by a hinge.  Monday and Friday lectures were augmented by Wednesday labs for which the class had been partitioned into groups of 75, 75, and 80 students seated in wide rows behind fixed computer monitors.  

I had studied the statistics education literature.  I had learned about theory and practice of efficient pedagogy.  But how was I supposed to do this in a class that was an order of magnitude larger than the ones that seemed to permeate the literature I had studied? 


## Get to the point...

Some ideas about *teaching* SBI in a large class environment.  Some people are heroically charasmatic lecturers

These are organized as separate thoughts, but they blend together...

## Pedagogical opportunities: Large enrollment  
- Large sample size for student generated data (GAISE, 2016)
    - reliable demonstrations of asymptotic properties (e.g. CLT) using data generated in-class
    - unusual observations often generated in-class
        - outliers (e.g. wrong units & typos)
        - legitimate extreme obs. (the tails are real)
        - sensitivity analysis discussions
- (Anonymous) Engagement  
    - Crowd-sourced Q&A  
    - Live SMS inbox  
    - Clickers 
        - instant feedback  
        - instant run-off  
- Google Sheets, Forms, & other tools facilitate live capture of data for immediate use
- GAISE (2016) includes much more support for large classes

## Pedagogical opportunities: Intersection of SBI & large enrollment   
- Example: m&m activity in lecture  
    - Live capture in Google Sheet
    - class approximates a sampling distribution  
    - student builds bootstrap distribution  
    - tangible comparison of sampling dist & bootstrap dist  
- Example: StatKey on smart phones (during lecture)  
    - accessible & scalable technology integration  
    - partner work (one run the app; one take notes)  





#### [cut]
Frequently this involves a conceptual multiple choice question on the screen scored only for participation.  With the software I'm using, I can show them a histogram of the responses either while the poll is still open or after I close it.  If you're wondering whether students care about getting the right answer on a completely anonymous poll scored only for participation (out of maybe 150 during the semester) try this: while students are voting (i.e. the poll is open) show the histogram and tell them the correct answer.  I've noticed that the *vast* majority of students eventually change their answer when I play this little game.  By the way, they usually don't know that I'm playing it... it would appear we're just discussing the correct answer with the histogram showing and had not bothered to shut off the poll (to be fair, that happens too)


#### [cut]
A few weeks before starting my position at Penn State, I found myself seated next to Michael Bulmer at dinner before an informal seminar where he was about to share how he was using his outstanding tool--the Islands (<https://islands.smp.uq.edu.au/>)--as a resource for class projects.  I explained how much I appreciated his work, but struggled to imagine how to manage it for projects in this incredibly large class I was to begin.  He gave a number of insightful suggestions before I asked about the enrollment in his class.  His class has 1000 students.  I find myself second guessing that his class actually is that large, so I started to do an Internet search to see if the enrollment was posted publicly.  Just as I was making my way to what seemed to be the right page, I decided to stop.  It occurred to me that the remark has has such an empowering impact for me, that I didn't want to risk spoiling it with the truth.  I think he teaches a class of 1000 students



## References

\hangindent=0.7 cm Ernst, M. D. (2004). Permutation methods: A basis for exact inference. *Statistical Science, 19*(4), p. 676-685.  

\hangindent=0.7 cm GAISE College Report ASA Revision Committee (2016). *Guidelines for Assessment and Instruction in Statistics Education College Report 2016*, http://www.amstat.org/education/gaise.


\hangindent=0.7 cm Rossman, A. J. (2008). Reasoning about informal statistical inference: One statistician's view. *Statistics Education Research Journal 7*(2), p. 5-9.

\fi

